{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henriqueyjw/PROSECUTORIAL_INDEPENDENCE/blob/main/identificacao_politicos_Pesquisa_FabioKercher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pesquisa Partes Interesse STF\n",
        "\n",
        "Objetivo: Identificar, dada uma planilha de pessoas que sofreram processo pelo PGR, quais delas são políticos."
      ],
      "metadata": {
        "id": "spEGj456R02n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurações"
      ],
      "metadata": {
        "id": "pMnzW-F3oe_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjWbRWy0a8Ps",
        "outputId": "0d16c1c5-a932-49ab-c821-45a0d67271cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (3.14.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRJ0z-LzQ_Bh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import unicodedata\n",
        "from rapidfuzz import process, fuzz\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_acentos(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return texto\n",
        "    nfkd = unicodedata.normalize('NFKD', texto)\n",
        "    return ''.join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "\n",
        "def remover_preposicoes(nome):\n",
        "    \"\"\"\n",
        "    Remove as preposições 'de', 'das', 'dos', 'do', 'da' de um nome.\n",
        "    \"\"\"\n",
        "    if not isinstance(nome, str):\n",
        "        return nome\n",
        "    # Regex: ^|\\s para pegar no início ou com espaço antes, (?i) para ignorar maiúsculas/minúsculas\n",
        "    nome_sem_preposicoes = re.sub(r\"(?i)\\b(de|das|dos|do|da)\\b\\s*\", \"\", nome.lower()).strip()\n",
        "    return nome_sem_preposicoes.upper()\n",
        "\n",
        "def limpar_espacos(nome):\n",
        "    \"\"\"\n",
        "    Remove espaços extras entre nomes e no início/fim da string.\n",
        "    \"\"\"\n",
        "    if not isinstance(nome, str):\n",
        "        return nome\n",
        "    # Divide por espaços, remove strings vazias e junta as palavras com um único espaço\n",
        "    return ' '.join(nome.split())\n",
        "\n",
        "def normalizar_nome(nome):\n",
        "    if not isinstance(nome, str):\n",
        "        return ''\n",
        "    nome = remover_acentos(nome)\n",
        "    nome = remover_preposicoes(nome)\n",
        "    nome = limpar_espacos(nome)\n",
        "    nome = nome.upper()\n",
        "    nome = nome.strip()\n",
        "    return nome\n",
        "\n",
        "def deduplica_nomes_fuzzy(df, coluna, threshold=85):\n",
        "    nomes = df[coluna].dropna().unique()\n",
        "    usados = set()\n",
        "    resultado = []\n",
        "    for nome in nomes:\n",
        "        if nome in usados:\n",
        "            continue\n",
        "        similares = process.extract(\n",
        "            nome,\n",
        "            nomes,\n",
        "            scorer=fuzz.ratio,\n",
        "            limit=None\n",
        "        )\n",
        "        # Seleciona nomes acima do limiar de similaridade\n",
        "        grupo = [n for n, p, _ in similares if p >= threshold and n not in usados]\n",
        "        # Mantém o nome mais longo do grupo\n",
        "        nome_representante = max(grupo, key=len)\n",
        "        resultado.append(nome_representante)\n",
        "        usados.update(grupo)\n",
        "    # Cria DataFrame apenas com nomes deduplicados\n",
        "    return pd.DataFrame({coluna: resultado})\n",
        "\n",
        "def deduplica_nomes_fuzzy_mapping(df, coluna, threshold=85):\n",
        "    nomes = df[coluna].dropna().unique()\n",
        "    usados = set()\n",
        "    grupos = []\n",
        "    for nome in nomes:\n",
        "        if nome in usados:\n",
        "            continue\n",
        "        similares = process.extract(\n",
        "            nome,\n",
        "            nomes,\n",
        "            scorer=fuzz.ratio,\n",
        "            limit=None\n",
        "        )\n",
        "        # Seleciona nomes acima do limiar de similaridade\n",
        "        grupo = [n for n, p, _ in similares if p >= threshold and n not in usados]\n",
        "        # Mantém o nome mais longo do grupo\n",
        "        nome_representante = max(grupo, key=len)\n",
        "        grupos.append((grupo, nome_representante))\n",
        "        usados.update(grupo)\n",
        "    # Cria mapeamento para substituir\n",
        "    mapping = {}\n",
        "    for grupo, representante in grupos:\n",
        "        for nome in grupo:\n",
        "            mapping[nome] = representante\n",
        "    return mapping\n"
      ],
      "metadata": {
        "id": "2HuiieURbyMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importação de Dados"
      ],
      "metadata": {
        "id": "89Fdzzi1Twos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados das Partes processadas"
      ],
      "metadata": {
        "id": "Ky4QZWeUT5MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse = pd.read_excel('partes_interesse_stf.xlsx')"
      ],
      "metadata": {
        "id": "iraO_RzTUEce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Ano mais antigo dos dados: {df_interesse[\"ano\"].min()}')\n",
        "print(f'Ano mais recente dos dados: {df_interesse[\"ano\"].max()}')\n",
        "print(f'Qtd de Linhas: {df_interesse.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1iHWJ_xSJ9R",
        "outputId": "bdd1aac8-f8eb-4fb7-d014-6d90f8302783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ano mais antigo dos dados: 1995\n",
            "Ano mais recente dos dados: 2023\n",
            "Qtd de Linhas: 7103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados da Justiça Eleitoral. Todos os candidatos das eleições de 1994 até 2022"
      ],
      "metadata": {
        "id": "Ug24FbOST7qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para a pasta\n",
        "caminho_pasta = '/content/candidatos/'\n",
        "\n",
        "# Lista todos os arquivos .csv na pasta\n",
        "arquivos = glob.glob(os.path.join(caminho_pasta, '*.csv'))\n",
        "\n",
        "# Lê todos os arquivos em dataframes e concatena\n",
        "dfs = [pd.read_csv(arquivo, encoding='latin1', sep=';') for arquivo in arquivos]\n",
        "\n",
        "#df final\n",
        "df_eleitoral = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnEt_0lYUAUP",
        "outputId": "9c1f2941-8142-4fa9-b3f2-03a719fc8786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-120819715.py:8: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfs = [pd.read_csv(arquivo, encoding='latin1', sep=';') for arquivo in arquivos]\n",
            "/tmp/ipython-input-120819715.py:8: DtypeWarning: Columns (57) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfs = [pd.read_csv(arquivo, encoding='latin1', sep=';') for arquivo in arquivos]\n",
            "/tmp/ipython-input-120819715.py:8: DtypeWarning: Columns (61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfs = [pd.read_csv(arquivo, encoding='latin1', sep=';') for arquivo in arquivos]\n",
            "/tmp/ipython-input-120819715.py:8: DtypeWarning: Columns (20,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dfs = [pd.read_csv(arquivo, encoding='latin1', sep=';') for arquivo in arquivos]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tamanho df_eleitoral antes: {df_eleitoral.shape[0]}')\n",
        "df_eleitoral.drop_duplicates(subset=['NR_CPF_CANDIDATO', 'ANO_ELEICAO'], inplace=True)\n",
        "print(f'Tamanho df_eleitoral depois: {df_eleitoral.shape[0]}')"
      ],
      "metadata": {
        "id": "qgkiwqZskGWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c536a0e-4387-4242-cebc-86df0cbc98b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho df_eleitoral antes: 2902126\n",
            "Tamanho df_eleitoral depois: 2868483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpeza do DF_INTERESSE"
      ],
      "metadata": {
        "id": "CEudscqAUuu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse.rename(columns={'parte_interesse': 'parte_interesse_original'}, inplace=True)\n",
        "\n",
        "df_interesse['parte_interesse'] = (\n",
        "    df_interesse['parte_interesse_original']\n",
        "    .str.upper()  # deixar tudo maiúsculo\n",
        "    .str.split(' OU ')  # split pelo OU\n",
        "    .str[0]  # pega a primeira parte\n",
        "    .str.strip()  # tira espaços extras\n",
        ")\n",
        "\n",
        "# remove acentos\n",
        "df_interesse['parte_interesse'] = df_interesse['parte_interesse'].apply(remover_acentos)\n",
        "\n",
        "print(f'Qtd de Linhas (antes da remoção de empresa): {df_interesse.shape[0]}')\n",
        "\n",
        "# Pré-processamento para maiúsculo\n",
        "df_interesse['parte_interesse'] = df_interesse['parte_interesse'].str.upper()\n",
        "\n",
        "padrao_empresa_simplificado = (\n",
        "    r'REPRESENTANTE LEGAL'\n",
        "    r'|S\\.A'\n",
        "    r'|S/A'\n",
        "    r'|SINDICATO'\n",
        "    r'|PARTIDO'\n",
        "    r'|ASSOCIACAO'\n",
        "    r'|ASSOCIAÇAO'\n",
        "    r'|LTDA'\n",
        "    r'|SOCIEDADE'\n",
        "    r'|MINISTERIO PUBLICO'\n",
        "    r'|CONGREGACAO'\n",
        "    r'|CONGREGAÇAO'\n",
        "    r'|FUNDACAO'\n",
        "    r'|FUNDAÇAO'\n",
        "    r'|FUNDACAO PUBLICA'\n",
        "    r'|FUNDACAO PRIV'\n",
        "    r'|SOCIEDADE CIVIL'\n",
        ")\n",
        "\n",
        "padrao_sigla = r'^([A-Z]{1,4}\\.?[\\s]?){2,}$'\n",
        "\n",
        "empresa_mask = df_interesse['parte_interesse'].str.contains(padrao_empresa_simplificado, regex=True, na=False)\n",
        "\n",
        "\n",
        "df_interesse = df_interesse[~(empresa_mask)]\n",
        "\n",
        "\n",
        "print(f'Qtd de Linhas (depois da remoção de empresa): {df_interesse.shape[0]}')\n",
        "\n",
        "#remove duplicados\n",
        "df_interesse = df_interesse.drop_duplicates(subset='parte_interesse')\n",
        "\n",
        "print(f'Qtd de Linhas (depois da remoção de duplicado): {df_interesse.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYIewrTUxi1",
        "outputId": "3769bece-0425-4829-d55c-0f6e9a83478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qtd de Linhas (antes da remoção de empresa): 7103\n",
            "Qtd de Linhas (depois da remoção de empresa): 6989\n",
            "Qtd de Linhas (depois da remoção de duplicado): 4431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse['parte_interesse'] = df_interesse['parte_interesse'].apply(normalizar_nome)\n",
        "df_interesse.drop_duplicates(subset='parte_interesse', inplace=True)\n",
        "print(f'Qtd de Linhas (depois da normalização e remoção de duplicados): {df_interesse.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53LqDBSOpumW",
        "outputId": "22da89da-1c32-4ffa-e337-12c0de6a0000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qtd de Linhas (depois da normalização e remoção de duplicados): 4398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nomes = deduplica_nomes_fuzzy(df_interesse, \"parte_interesse\", threshold=75)\n",
        "print(f'Tamanho df_nomes (remoção com fuzzy): {df_nomes.shape[0]}')"
      ],
      "metadata": {
        "id": "cv84BKXXZRrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2177b17e-cec4-47c3-bb65-dab163f89ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho df_nomes (remoção com fuzzy): 3508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse = df_interesse[df_interesse[\"parte_interesse\"].isin(df_nomes[\"parte_interesse\"])].reset_index(drop=True)\n",
        "print(f'Tamanho df_interesse: {df_interesse.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxhrbEc44nPl",
        "outputId": "2341c884-deff-43fc-ec58-d15d7c104e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho df_interesse: 3508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge dos Dataframes com Fuzzy"
      ],
      "metadata": {
        "id": "46w65LxDfR88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padroniza\n",
        "df_nomes['nome_normalizado'] = df_nomes.iloc[:,0].apply(normalizar_nome)\n",
        "df_eleitoral['nome_normalizado'] = df_eleitoral['NM_CANDIDATO'].apply(normalizar_nome)\n",
        "lista_eleitoral = df_eleitoral['nome_normalizado'].dropna().unique()\n",
        "\n",
        "resultados = []\n",
        "threshold = 75  # Ajuste este valor se necessário\n",
        "\n",
        "def fuzzy_lote(df_nomes, lista_eleitoral, threshold=75, batch_size=500):\n",
        "    from rapidfuzz import process, fuzz\n",
        "\n",
        "    nomes = df_nomes['nome_normalizado'].tolist()\n",
        "    resultados = []\n",
        "\n",
        "    for i in range(0, len(nomes), batch_size):\n",
        "        nomes_batch = nomes[i:i+batch_size]\n",
        "        matches = process.cdist(\n",
        "            nomes_batch,\n",
        "            lista_eleitoral,\n",
        "            scorer=fuzz.token_sort_ratio,\n",
        "            workers=-1\n",
        "        )\n",
        "        melhor_indices = matches.argmax(axis=1)\n",
        "        melhor_scores = matches.max(axis=1)\n",
        "        # Adiciona resultados do lote\n",
        "        for nome, idx, score in zip(nomes_batch, melhor_indices, melhor_scores):\n",
        "            if score >= threshold:\n",
        "                resultados.append({\n",
        "                    'nome_normalizado': nome,\n",
        "                    'match_idx': idx,\n",
        "                    'match_score': score,\n",
        "                    'nome_match': lista_eleitoral[idx]\n",
        "                })\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# Batched fuzzy matching: consome MUITO MENOS RAM, ideal para grandes volumes\n",
        "df_nomes_matches = fuzzy_lote(df_nomes, lista_eleitoral, threshold=threshold, batch_size=500)\n",
        "\n",
        "# Merge com eleitoral\n",
        "df_historico_politico = pd.merge(\n",
        "    df_nomes_matches,\n",
        "    df_eleitoral,\n",
        "    left_on='nome_match',\n",
        "    right_on='nome_normalizado',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "bzvSGDSzfUPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for nome, dados in df_historico_politico.groupby('nome_normalizado_x'):\n",
        "    print(f\"\\nHistórico de: {nome}\")\n",
        "    print(dados[['ANO_ELEICAO', 'DS_CARGO', 'SG_PARTIDO', 'NM_URNA_CANDIDATO', 'NM_CANDIDATO', 'SG_UE']])"
      ],
      "metadata": {
        "id": "lgvFX5PTxl-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_historico_politico.to_csv('historico_politico.csv', index=False)\n",
        "df_historico_politico.to_excel('df_historico_politicos.xlsx')"
      ],
      "metadata": {
        "id": "ez1mGDtKwqw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Marcando como \"político\"\n",
        "\n",
        "Macando como \"político\" e colocando histórico da última eleição no df principal"
      ],
      "metadata": {
        "id": "_CoTCjlpgVBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse['nome_normalizado'] = df_interesse['parte_interesse'].apply(normalizar_nome)\n",
        "df_historico_politico['nome_normalizado'] = df_historico_politico['NM_CANDIDATO'].apply(normalizar_nome)\n",
        "\n",
        "# Como há múltiplos registros do mesmo político, pegamos o registro da eleição mais recente para cada nome\n",
        "df_historico_politico_ult = (\n",
        "    df_historico_politico.sort_values('ANO_ELEICAO', ascending=False)\n",
        "    .drop_duplicates('nome_normalizado')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Prepara lista de nomes políticos para fuzzy search\n",
        "nomes_politicos = df_historico_politico_ult['nome_normalizado'].tolist()\n",
        "\n",
        "# Função fuzzy de busca do histórico do político\n",
        "def busca_historico_fuzzy(nome):\n",
        "    nome_norm = normalizar_nome(nome)\n",
        "    melhor = process.extractOne(nome_norm, nomes_politicos, scorer=fuzz.token_sort_ratio)\n",
        "    # threshold pode ser ajustado (ex: 85 ou 90)\n",
        "    if melhor and melhor[1] >= 85:\n",
        "        nome_politico_encontrado = melhor[0]\n",
        "        poli_row = df_historico_politico_ult[df_historico_politico_ult['nome_normalizado'] == nome_politico_encontrado].iloc[0]\n",
        "        return pd.Series({\n",
        "            'politico': 'Sim',\n",
        "            'ANO_ELEICAO': poli_row['ANO_ELEICAO'],\n",
        "            'DS_CARGO': poli_row['DS_CARGO'],\n",
        "            'SG_PARTIDO': poli_row['SG_PARTIDO'],\n",
        "            'NM_URNA_CANDIDATO': poli_row['NM_URNA_CANDIDATO'],\n",
        "            'NM_CANDIDATO': poli_row['NM_CANDIDATO'],\n",
        "            'nome_politico_encontrado': nome_politico_encontrado,\n",
        "            'similaridade': melhor[1]\n",
        "        })\n",
        "    return pd.Series({\n",
        "        'politico': '',\n",
        "        'ANO_ELEICAO': '',\n",
        "        'DS_CARGO': '',\n",
        "        'SG_PARTIDO': '',\n",
        "        'NM_URNA_CANDIDATO': '',\n",
        "        'NM_CANDIDATO': '',\n",
        "        'nome_politico_encontrado': '',\n",
        "        'similaridade': ''\n",
        "    })\n",
        "\n",
        "# Aplica fuzzy search na coluna interesse\n",
        "df_interesse = df_interesse.join(df_interesse['parte_interesse'].apply(busca_historico_fuzzy))"
      ],
      "metadata": {
        "id": "6WayTdvQghec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_interesse.to_csv('df_interesse_sem_empresa_politicos.csv')\n",
        "df_interesse.to_excel('df_interesse_sem_empresa_politicos.xlsx')"
      ],
      "metadata": {
        "id": "XbXNkSuWwsuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}